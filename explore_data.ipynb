{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "\n",
    "import librosa # for mel-spectrogram estimation\n",
    "import soundfile as sf # for opening .flac audio\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20, 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=22):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'data/train'\n",
    "VAL_DIR = 'data/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_audio, framerate = sf.read('data/audio_samples/' + '20-205-0000.flac')\n",
    "noisy_audio, framerate = sf.read('data/audio_samples/' + '20-205-0000_noisy.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(clean_audio) / float(framerate)) # length in seconds\n",
    "print(len(noisy_audio) / float(framerate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized log-mel-spectrogram of clean and noisy audios\n",
    "clean_mel = 1 + np.log(1.e-12 + librosa.feature.melspectrogram(clean_audio, sr=16000, n_fft=1024, hop_length=256, fmin=20, fmax=8000, n_mels=80)).T / 10.\n",
    "noisy_mel = 1 + np.log(1.e-12 + librosa.feature.melspectrogram(noisy_audio, sr=16000, n_fft=1024, hop_length=256, fmin=20, fmax=8000, n_mels=80)).T / 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(clean_mel.T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(noisy_mel.T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(records):\n",
    "    max_length = max(record.shape[0] for record in records)\n",
    "    X = np.empty(shape=(len(records), input_length, 80))\n",
    "    for i, record in enumerate(records):\n",
    "        if len(record) < max_length:\n",
    "            max_offset = max_length - len(record)\n",
    "            offset = np.random.randint(max_offset) if max_offset else max_offset\n",
    "            record = np.pad(record, ((max_offset, 0), (0, 0)), \"constant\")\n",
    "        X[i,] = record\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(directory):\n",
    "    clean_path = os.path.join(directory, 'clean')\n",
    "    noisy_path = os.path.join(directory, 'noisy')\n",
    "    for subdir in os.listdir(clean_path):\n",
    "        clean_samples = [np.load(f) for f in glob.glob(os.path.join(clean_path, '{}/*.npy'.format(subdir)))]\n",
    "        clean_lables = np.zeros(len(batch))\n",
    "        yield clean_samples, clean_lables\n",
    "        noisy_samples = [np.load(f) for f in glob.glob(os.path.join(noisy_path, '{}/*.npy'.format(subdir)))]\n",
    "        noisy_lables = np.ones(len(noisy_samples))\n",
    "        yield noisy_samples, noisy_lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, tagset_size):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.dropout_layer = torch.nn.Dropout(p=0.2)\n",
    "        self.hidden2out = torch.nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        outputs, (ht, ct) = self.lstm(sentence.view(sentence.shape[1], sentence.shape[0], self.embedding_dim))\n",
    "        output = self.dropout_layer(ht[-1])\n",
    "        output = self.hidden2out(output)\n",
    "        return torch.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loss, optimizer, num_epochs, scheduler=None):\n",
    "    loss_history = []\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        loss_accum = 0\n",
    "        correct_samples = 0\n",
    "        total_samples = 0\n",
    "        for batch, lables in get_batch(TRAIN_DIR):\n",
    "            optimizer.zero_grad()\n",
    "            x_gpu = torch.tensor(prepare_data(batch), dtype=torch.float32).cuda()\n",
    "            y_gpu = torch.tensor(lables, dtype=torch.float32).view(len(lables), 1).cuda()\n",
    "            prediction = model(x_gpu)\n",
    "            loss_value = loss(prediction, y_gpu)\n",
    "            loss_value.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            indices = (prediction > THRESHOLD).float()\n",
    "            correct_samples += torch.sum(indices == y_gpu)\n",
    "            loss_accum += loss_value\n",
    "                \n",
    "            total_samples += len(batch)\n",
    "            \n",
    "        ave_loss = loss_accum / total_samples\n",
    "        loss_history.append(float(ave_loss))\n",
    "        \n",
    "        train_accuracy = float(correct_samples) / total_samples\n",
    "        train_history.append(train_accuracy)\n",
    "        \n",
    "        val_accuracy = compute_accuracy(model)\n",
    "        val_history.append(val_accuracy)\n",
    "        \n",
    "        print(\"Average loss: {}, Train accuracy: {}, Val accuracy: {}\".format(\n",
    "            ave_loss, train_accuracy, val_accuracy))\n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "    return loss_history, train_history, val_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model):\n",
    "    model.eval()\n",
    "    \n",
    "    accuracy = 0\n",
    "    correct_samples = 0\n",
    "    total_samples = 0\n",
    "    for batch, lables in get_batch(VAL_DIR):\n",
    "        x_gpu = torch.tensor(prepare_data(batch), dtype=torch.float32).cuda()\n",
    "        y_gpu = torch.tensor(lables, dtype=torch.float32).view(len(lables), 1).cuda()\n",
    "        prediction = model(x_gpu)\n",
    "\n",
    "        indices = (prediction > THRESHOLD).float()\n",
    "        correct_samples += torch.sum(indices == y_gpu)\n",
    "            \n",
    "        total_samples += len(batch)\n",
    "    if total_samples:\n",
    "        accuracy = correct_samples.data.float() / total_samples\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.017475, Train accuracy: 0.903167, Val accuracy: 0.929250\n",
      "Average loss: 0.013535, Train accuracy: 0.920667, Val accuracy: 0.949250\n",
      "Average loss: 0.011492, Train accuracy: 0.940125, Val accuracy: 0.969000\n",
      "Average loss: 0.008295, Train accuracy: 0.953875, Val accuracy: 0.964000\n",
      "Average loss: 0.008262, Train accuracy: 0.955500, Val accuracy: 0.973750\n",
      "Average loss: 0.006170, Train accuracy: 0.975375, Val accuracy: 0.985250\n",
      "Average loss: 0.004460, Train accuracy: 0.982792, Val accuracy: 0.985500\n",
      "Average loss: 0.004288, Train accuracy: 0.987458, Val accuracy: 0.991750\n",
      "Average loss: 0.003578, Train accuracy: 0.990417, Val accuracy: 0.987750\n",
      "Average loss: 0.004559, Train accuracy: 0.983375, Val accuracy: 0.990250\n",
      "Average loss: 0.002984, Train accuracy: 0.991792, Val accuracy: 0.996500\n",
      "Average loss: 0.002031, Train accuracy: 0.994625, Val accuracy: 0.989500\n",
      "Average loss: 0.002782, Train accuracy: 0.989125, Val accuracy: 0.993250\n",
      "Average loss: 0.001641, Train accuracy: 0.995958, Val accuracy: 0.993500\n",
      "Average loss: 0.002147, Train accuracy: 0.993708, Val accuracy: 0.992250\n",
      "Average loss: 0.001906, Train accuracy: 0.994417, Val accuracy: 0.994250\n",
      "Average loss: 0.001608, Train accuracy: 0.996042, Val accuracy: 0.994750\n",
      "Average loss: 0.001675, Train accuracy: 0.995250, Val accuracy: 0.993750\n",
      "Average loss: 0.001895, Train accuracy: 0.994250, Val accuracy: 0.994000\n",
      "Average loss: 0.001703, Train accuracy: 0.995000, Val accuracy: 0.995500\n"
     ]
    }
   ],
   "source": [
    "seed_torch()\n",
    "model = LSTMTagger(80, 14, 1).cuda()\n",
    "loss_function = nn.BCELoss().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "loss_history, train_history, val_history = train_model(model, loss_function, optimizer, 20, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, mel):\n",
    "    x_gpu = torch.tensor(mel, dtype=torch.float32).cuda()\n",
    "    prediction = model(x_gpu.unsqueeze(0))\n",
    "    return (prediction > THRESHOLD).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model, test_mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
